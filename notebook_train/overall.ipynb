{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성된 학습용 데이터 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.combine import SMOTEENN\n",
    "from impyute.imputation.cs import mice\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력데이터 불러오기\n",
    "raw_data = pd.read_csv('check5_독립변수_전처리전.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상값을 결측치로 변경 : -999 -> Nan\n",
    "raw_data = raw_data.replace(-999.0, np.NaN)\n",
    "\n",
    "# 변수별 결측치 존재여부 확인_결측제거 전\n",
    "plt.figure(figsize = (12, 8))\n",
    "sns.heatmap(raw_data.isnull(), cbar=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MICE를 이용하여 결측치를 대치\n",
    "# 결측치가 제거된 데이터값 : eli_null\n",
    "eli_null = mice(raw_data.values)\n",
    "\n",
    "# 결측치가 제거된 데이터값을 다시 취합\n",
    "in_data = pd.DataFrame(data = eli_null, columns = raw_data.columns)\n",
    "in_data = in_data.clip(lower = 0)\n",
    "\n",
    "# 변수별 결측치 존재여부 확인_결측제거 후\n",
    "plt.figure(figsize = (12, 8))\n",
    "sns.heatmap(in_data.isnull(), cbar=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수간 상관계수 확인\n",
    "corr_check = in_data.corr()\n",
    "\n",
    "# 상관관계 heatmap 생성\n",
    "# annnot : 실제값 표시\n",
    "# cmap : 색상\n",
    "# vmin, vmax : 컬러차트 영역 설정\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "sns.heatmap(corr_check, annot = True, cmap = 'Pastel1_r', vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중공산성 고려를 위한 변수별 VIF값 생성\n",
    "vif = pd.DataFrame(data = [variance_inflation_factor(in_data.values, i) for i in range(8)], index = in_data.columns, columns = ['VIF'])\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = in_data.reset_index().rename(columns = {'index' : 'grid'})\n",
    "in_data.to_csv('check6_1_입력데이터_결측제거.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상치 제거\n",
    "# 4분위수의 iqr*1.5만큼의 외부 범위를 제외한 데이터를 outlier로 간주\n",
    "# 각 범위를 lbd, ubd로 계산\n",
    "qut = in_data.describe().loc[['25%', '75%'], '고속도로':'주차장'].T\n",
    "qut['iqr'] = qut['75%'] - qut['25%']\n",
    "qut['lbd'], qut['ubd'] = qut['25%'] - 1.5 * qut['iqr'], qut['75%'] + 1.5 * qut['iqr']\n",
    "\n",
    "# outlier 데이터는 'count'를 NaN으로 변경\n",
    "for idx, srs in in_data.iterrows():\n",
    "  if (qut['lbd'] < srs['고속도로':'주차장']).all() and (srs['고속도로':'주차장'] < qut['ubd']).all():\n",
    "    continue\n",
    "  else:\n",
    "    in_data.at[idx, 'grid'] = -1\n",
    "in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier 내부의 데이터만 추출\n",
    "cpl_data = in_data[in_data['grid'] != -1]\n",
    "cpl_data.to_csv('check6_2_입력데이터_결측제거_이상치제거.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "# 입력데이터 불러오기\n",
    "\n",
    "# MinMaxScaling 이용\n",
    "# 스케일된 데이터 저장\n",
    "X = cpl_data.loc[:, '고속도로':'주차장'].values\n",
    "scaled_X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "# X1 : 스케일링된 데이터프레임\n",
    "# X2 : 분석에 사용될 feature\n",
    "X1 = pd.DataFrame(data = scaled_X, columns = raw_data.columns[1:])\n",
    "X2 = cpl_data['grid'].reset_index().drop(columns = 'index', axis=1)\n",
    "\n",
    "# 완성형 입력데이터 생성\n",
    "cpl_data = pd.concat([X1, X2], axis=1)\n",
    "cpl_data.to_csv('check6_3_입력데이터_결측제거_이상치제거_스케일링.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 결합\n",
    "drive_grid = pd.read_csv('/content/check4_2_운행_좌표그리드.csv', index_col = 0)\n",
    "gby1 = drive_grid.pivot_table(index = 'grid', aggfunc = 'count', values = 's_lat').rename(columns = {'s_lat' : 'count'})\n",
    "\n",
    "input_data = pd.merge(cpl_data, gby1, left_on = 'grid', right_index = True, how = 'left').fillna(0)\n",
    "input_data.to_csv('check7_최종데이터.csv')\n",
    "\n",
    "\n",
    "trans_gird = pd.read_csv('/content/check4_3_대중교통_좌표그리드.csv', index_col = 0)\n",
    "gby1 = trans_gird.pivot_table(index = 'grid', aggfunc = 'count', values = 'lat').rename(columns = {'lat' : 'count'})\n",
    "\n",
    "trans_data = pd.merge(cpl_data, gby1, left_on = 'grid', right_index = True, how = 'left').fillna(0)\n",
    "trans_data.to_csv('check8_비교데이터_대중교통.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 및 샘플링\n",
    "\n",
    "# 이진분류모델을 사용하기 위해, 'count'값이 1 이상이면 모두 1로 집계\n",
    "def binary(n):\n",
    "  if n == 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return 1\n",
    "\n",
    "input_data['count'] = input_data['count'].apply(binary)\n",
    "\n",
    "# 'count'의 비율 확인\n",
    "# input_data (운행이력) _ 33921 : 1962 (불균형)\n",
    "input_data['count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수, 종속변수 분리\n",
    "X = input_data.loc[:, '고속도로':'주차장']\n",
    "y = input_data['count']\n",
    "\n",
    "# 분리한 데이터가 불균형을 이루지 않도록, 비율에 맞게 분리\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "for train_idx, test_idx in split.split(X, y):\n",
    "  df_strat_train = input_data.loc[train_idx]\n",
    "  df_strat_test = input_data.loc[test_idx]\n",
    "\n",
    "# train, test 데이터 생성\n",
    "X_train_car, y_train_car = df_strat_train.loc[:, '고속도로':'주차장'], df_strat_train['count']\n",
    "X_test_car, y_test_car = df_strat_test.loc[:, '고속도로':'주차장'], df_strat_test['count']\n",
    "\n",
    "\n",
    "# train, test로의 분리 시각화\n",
    "sep_train = pd.concat([X_train_car, y_train_car], axis = 1)\n",
    "sep_train['group'] = 'train'\n",
    "sep_test = pd.concat([X_test_car, y_test_car], axis = 1)\n",
    "sep_test['group'] = 'test'\n",
    "\n",
    "sep = pd.concat([sep_train, sep_test], axis = 0)\n",
    "\n",
    "df_group_by_0 = sep[sep['count']==0].groupby(['group']).count()\n",
    "df_group_by_1 = sep[sep['count']==1].groupby(['group']).count()\n",
    "label = sep['group'].unique()\n",
    "label = sorted(label)\n",
    "index = np.arange(len(label))\n",
    "\n",
    "p1 = plt.bar(index, np.array(df_group_by_0)[:, 0], color='navy', alpha=0.5, width=0.45)\n",
    "p2 = plt.bar(index+0.45, np.array(df_group_by_1)[:, 0], color='gray', alpha=0.5, width=0.45)\n",
    "plt.xticks(index,label)\n",
    "plt.legend((p1[0], p2[0]), ('0', '1'), fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEENN 기법을 활용하여, 다수클래스를 줄이고 소수클래스를 늘림\n",
    "smt = SMOTEENN(random_state = 42)\n",
    "X_car, y_car = smt.fit_resample(X_train_car, y_train_car)\n",
    "\n",
    "# 'count'의 비율 확인\n",
    "# 1 : 0 = 23215 : 19676\n",
    "y_car.value_counts()\n",
    "y_car.value_counts().plot(kind = 'bar', color = 'darkorange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catboost\n",
    "# 운행 데이터를 모델에 적용\n",
    "cat = CatBoostClassifier(iterations=5, depth=4, learning_rate=0.49, loss_function='Logloss', verbose=True)\n",
    "cat.fit(X_car, y_car)\n",
    "\n",
    "preds_class = cat.predict(X_test_car)\n",
    "preds_proba = cat.predict_proba(X_test_car)\n",
    "\n",
    "accuracy = accuracy_score(y_test_car, preds_class)\n",
    "recall = recall_score(y_test_car, preds_class)\n",
    "\n",
    "print('class = ', preds_class)\n",
    "print('proba = ', preds_proba, sep = '\\n', end='\\n\\n')\n",
    "print('accuray =', accuracy)\n",
    "print('recall =', recall, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "# 운행 데이터를 모델에 적용\n",
    "xgb_clf = XGBClassifier(min_child_weight = 3, max_depth = 3, sub_sample = 0.7,learning_rate = 0.2, n_estimators = 60)\n",
    "xgb_clf.fit(X_car, y_car)\n",
    "\n",
    "y_pred = xgb_clf.predict(X_test_car)\n",
    "\n",
    "ac = accuracy_score(y_test_car, y_pred)\n",
    "r = recall_score(y_test_car, y_pred)\n",
    "print('accuray =', ac)\n",
    "print('recall =', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM\n",
    "# 운행 데이터를 모델에 적용\n",
    "lgbm_clf = LGBMClassifier(n_estimators = 400)\n",
    "lgbm_clf.fit(X_car, y_car)\n",
    "\n",
    "y_pred = lgbm_clf.predict(X_test_car)\n",
    "\n",
    "ac = accuracy_score(y_test_car, y_pred)\n",
    "r = recall_score(y_test_car, y_pred)\n",
    "print('accuray =', ac)\n",
    "print('recall =', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "# 운행 데이터를 모델에 적용\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5)\n",
    "classifier.fit(X_car, y_car)\n",
    "\n",
    "y_pred = classifier.predict(X_test_car)\n",
    "\n",
    "ac = accuracy_score(y_test_car, y_pred)\n",
    "r = recall_score(y_test_car, y_pred)\n",
    "print('accuray =', ac)\n",
    "print('recall =', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV + RandomForest\n",
    "# 최적 하이퍼 파라미터 찾기 _ 운행이력\n",
    "params = { 'n_estimators' : [10, 100],\n",
    "           'max_depth' : [6, 8, 10, 12],\n",
    "           'min_samples_leaf' : [6, 8, 10, 12],\n",
    "           'min_samples_split' : [6, 8, 10, 12]\n",
    "            }\n",
    "\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state = 0, n_jobs = -1)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 3, n_jobs = -1)\n",
    "grid_cv.fit(X_car, y_car)\n",
    "\n",
    "\n",
    "# 최적 하이퍼 파라미터로, 운행 데이터를 모델에 적용\n",
    "rf_clf1 = RandomForestClassifier(n_estimators = 100, \n",
    "                                max_depth = 12,\n",
    "                                min_samples_leaf = 6,\n",
    "                                min_samples_split = 6,\n",
    "                                random_state = 0,\n",
    "                                n_jobs = -1)\n",
    "rf_clf1.fit(X_car, y_car)\n",
    "y_pred = rf_clf1.predict(X_test_car)\n",
    "\n",
    "ac = accuracy_score(y_test_car, y_pred)\n",
    "r = recall_score(y_test_car, y_pred)\n",
    "print('accuray =', ac)\n",
    "print('recall =', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Search + RandomForest\n",
    "# 운행 데이터를 모델에 적용\n",
    "rf_clf2 = RandomForestClassifier(n_estimators = 100, \n",
    "                                max_depth = 8,\n",
    "                                min_samples_leaf = 4,\n",
    "                                min_samples_split = 6,\n",
    "                                random_state = 0,\n",
    "                                n_jobs = -1)\n",
    "rf_clf2.fit(X_car, y_car)\n",
    "y_pred = rf_clf2.predict(X_test_car)\n",
    "\n",
    "ac = accuracy_score(y_test_car, y_pred)\n",
    "r = recall_score(y_test_car, y_pred)\n",
    "print('accuray =', ac)\n",
    "print('recall =', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Ensemble\n",
    "def stacking_data(model, X_train, y_train, X_test, n_folds=3):     \n",
    "  kfold = StratifiedKFold(n_splits = n_folds, random_state = 1004,shuffle=True)\n",
    "  \n",
    "  # 최종 모델에서 사용할 데이터 셋 세팅 (0 값으로)\n",
    "  # 만약 shape가 (100,10)이었으면 폴드의 검증 과정 중 저장할 데이터는 (100,1)으로 함.\n",
    "  train_fold_predict = np.zeros((X_train.shape[0],1))\n",
    "  # test 는 X_test 값을 이용해서 매 폴드마다 예측을 하기 때문에 (100, fold갯수) 모양이다.\n",
    "  # 해당 폴드마다 X_test의 예측 값을 fold 에 넣는다! meta model 이 쓸꺼임\n",
    "  test_predict = np.zeros((X_test.shape[0], n_folds))\n",
    "  print('model : ',model.__class__.__name__)\n",
    "  \n",
    "  for cnt, (train_index, valid_index) in enumerate(kfold.split(X_train,y_train)):\n",
    "    X_train_ = X_train.iloc[train_index]\n",
    "    y_train_ = y_train.iloc[train_index]\n",
    "    X_valid = X_train.iloc[valid_index]\n",
    "\n",
    "    # 학습\n",
    "    model.fit(X_train_,y_train_)\n",
    "    # 해당 폴드에서 학습된 모델에다가 검증 데이터 (X_valid)로 예측 후 저장\n",
    "    train_fold_predict[valid_index,:] = model.predict(X_valid).reshape(-1,1)\n",
    "    # 해당 폴드에서 생성된 모델에게 원본 테스트 데이터 (X_test)를 이용해서 예측하고 저장\n",
    "    test_predict[:,cnt] = model.predict(X_test)\n",
    "  \n",
    "  # for 문이 끝나면 test_pred는 평균을 내서 하나로 합친다.\n",
    "  test_predict_mean = np.mean(test_predict, axis=1).reshape(-1,1)\n",
    "  \n",
    "  return train_fold_predict, test_predict_mean\n",
    "\n",
    "\n",
    "xgb_esti=XGBClassifier(random_state=0,base_estimator__max_depth=2,base_estimator__min_child_weight=2,base_estimator__sub_sample=0.5,n_estimators=140,learning_rate=0.3)\n",
    "cat_esti=CatBoostClassifier(random_state=0,depth=5,learning_rate=0.3,n_estimators=100)\n",
    "rf_esti = RandomForestClassifier(n_jobs=-1,n_estimators=100,max_depth=8)\n",
    "lgbm_est=LGBMClassifier(n_jobs=-1, random_state=0,n_estimators=100)\n",
    "gb_est=GradientBoostingClassifier(random_state=0)\n",
    "dt_est=DecisionTreeClassifier(random_state=0)\n",
    "ada_est=AdaBoostClassifier(random_state=0)\n",
    "\n",
    "\n",
    "# 앙상블 수행 cat, rf, lgbm, GradientBoosting, dt, adaboost ->  xgb\n",
    "cat_train, cat_test = stacking_data(cat_esti, X_car, y_car, X_test_car)\n",
    "rf_train, rf_test = stacking_data(rf_esti, X_car, y_car, X_test_car)\n",
    "lgbm_train, lgbm_test = stacking_data(lgbm_est, X_car, y_car, X_test_car)\n",
    "gb_train, gb_test = stacking_data(gb_est, X_car, y_car, X_test_car)\n",
    "dt_train, dt_test = stacking_data(dt_est, X_car, y_car, X_test_car)\n",
    "ada_train, ada_test = stacking_data(ada_est, X_car, y_car, X_test_car)\n",
    "\n",
    "\n",
    "# return 된 kfold 결과와 X_test 결과를 skacking\n",
    "# 이 new data를 meta data로 최종 model 을 학습 시키기위해 준비\n",
    "new_X_train = np.concatenate((cat_train, rf_train, lgbm_train, gb_train, dt_train, ada_train), axis=1)\n",
    "new_X_test = np.concatenate((cat_test,rf_test,lgbm_test,gb_test,dt_test,ada_test), axis=1)\n",
    "\n",
    "print('원본 : ', X_car.shape, X_test_car.shape)\n",
    "print('새로운 : ', new_X_train.shape, new_X_test.shape)\n",
    "\n",
    "# 최종 모델 훈련\n",
    "xgb_esti.fit(new_X_train, y_car)\n",
    "stack_pred = xgb_esti.predict(new_X_test)\n",
    "\n",
    "print('accuracy = ', accuracy_score(y_test_car, stack_pred))\n",
    "print(\"recall = {:.4f}\".format(recall_score(y_test_car, stack_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델성능 확인 및 서비스 발전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import folium\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선정된 모델 및 데이터로 성능검토\n",
    "rf_clf2_car = RandomForestClassifier(n_estimators = 100, \n",
    "                                max_depth = 8,\n",
    "                                min_samples_leaf = 4,\n",
    "                                min_samples_split = 6,\n",
    "                                random_state = 0,\n",
    "                                n_jobs = -1)\n",
    "rf_clf2_car.fit(X_car, y_car)\n",
    "y_pred = rf_clf2_car.predict(X_test_car)\n",
    "\n",
    "ac = accuracy_score(y_test_car, y_pred)\n",
    "r = recall_score(y_test_car, y_pred)\n",
    "print('accuray_car =', ac)\n",
    "print('recall_car =', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 운행 데이터의 train set에 대한 과적합 여부 확인\n",
    "y_aftrain = rf_clf2_car.predict(X_train_car)\n",
    "ac = accuracy_score(y_train_car, y_aftrain)\n",
    "r = recall_score(y_train_car, y_aftrain)\n",
    "\n",
    "print('accuray =', ac)\n",
    "print('recall =', r)\n",
    "\n",
    "# 결과 : 과적합 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 운행여부를 결정하는, 중요도가 높은 feature를 선정\n",
    "feature_importance_car = rf_clf2_car.feature_importances_\n",
    "\n",
    "# Top 중요도로 정렬하고, 쉽게 시각화하기 위해 Series 변환\n",
    "visual_imp_car = pd.Series(feature_importance_car, index = X_train_car.columns)\n",
    "\n",
    "# 중요도값 순으로 Series를 정렬\n",
    "feature_top_car = visual_imp_car.sort_values(ascending=False)\n",
    "plt.figure(figsize = [10, 6])\n",
    "plt.title('Feature Importances')\n",
    "sns.barplot(x = feature_top_car, y = feature_top_car.index, palette = \"Oranges_r\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 운행 데이터의 중요 변수 3개 추출\n",
    "top3_car = feature_top_car[:4]\n",
    "top3_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix 생성\n",
    "\n",
    "label=['no','yes'] # 라벨 설정\n",
    "plot1 = plot_confusion_matrix(rf_clf2_car, # 분류 모델\n",
    "                             X_test_car, y_test_car, # 예측 데이터와 예측값의 정답(y_true)\n",
    "                             display_labels=label, # 표에 표시할 labels\n",
    "                             cmap=plt.cm.Reds, # 컬러맵(plt.cm.Reds, plt.cm.rainbow 등이 있음)\n",
    "                             #normalize='true') # 'true', 'pred', 'all' 중에서 지정 가능. default=None\n",
    ")\n",
    "plot1.ax_.set_title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 중 주차장 후보지 선정\n",
    "# 다음 조건을 모두 만족하는 격자 추출\n",
    "\n",
    "# 실제로 주차장이 없는 곳 ('count' = 0)\n",
    "# 주차장이 있다고 예측된 곳 ('pred_car' = 1)\n",
    "# 대중교통 역이 실제로 없는 곳 ('trans' = 0)\n",
    "\n",
    "trans = pd.read_csv('check8_비교데이터_대중교통.csv', index_col=0)\n",
    "\n",
    "pred_car = rf_clf2_car.predict(X_test_car)\n",
    "pred_car = pd.Series(pred_car, index = y_test_car.index)\n",
    "trans = trans[['grid', 'count']]\n",
    "\n",
    "cand = X_test_car\n",
    "cand = pd.concat([cand, y_test_car, pred_car], axis=1).rename(columns = {0 : 'pred_car'})\n",
    "cand = pd.merge(cand, trans, left_index = True, right_on = 'grid', how = 'left')\n",
    "\n",
    "cand.index = cand['grid']\n",
    "cand = cand.rename(columns = {'count_x' : 'count', 'count_y' : 'trans'})\n",
    "cand['trans'] = cand['trans'].fillna(0).apply(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 중 주차장 후보지 격자 추출\n",
    "park = cand[(cand['count'] == 0) & (cand['pred_car'] == 1) & (cand['trans'] == 0)]\n",
    "\n",
    "# 1141개의 후보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 후보 중 분석할 2개의 위치 임의추출\n",
    "import random\n",
    "random.seed(0)\n",
    "analy = random.sample(list(park.index), k=2)\n",
    "\n",
    "# 해당 격자의 위치정보 추출\n",
    "center = pd.read_csv('check3_1_그리드_중심정보.csv', index_col = 0)\n",
    "polygon = pd.read_csv('check3_2_그리드_좌표정보.csv', index_col = 0)\n",
    "\n",
    "center = center.loc[analy, :]\n",
    "polygon = polygon.loc[analy, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석할 샘플 시각화\n",
    "map_analy = folium.Map(location = [36, 128])\n",
    "for i in analy:\n",
    "  folium.PolyLine(locations = np.append(np.array(polygon.loc[i].tolist()), np.array(polygon.loc[i].tolist())[:2]).reshape(-1, 2), fill = True, tooltip = 'Polyline').add_to(map_analy)\n",
    "\n",
    "map_analy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae5be987c148d89c84ff8b399e0419f7ec11403716def357a7532a299975b856"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
